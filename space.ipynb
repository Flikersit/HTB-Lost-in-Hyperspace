{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens\n",
      "['T' 'L' 'E' 'T' 'F' 'L' '1' 'E' 'Y' 'W' 'T' 'V' '3' '{' 'B' '8' '3' '4'\n",
      " '_' 'D' 'N' 'L' '#' 'I' 'C' '-' 'H' 'A' 'E' '4' 'C' '5' 'L' 'W' 'I' 'O'\n",
      " '4' '{' 'M' '!' '_' '{' 'X' '}' '8' '4' 'B' 'E' 'F' 'Q' 'A' '_' '}' 'V'\n",
      " 'M' '1' 'S' 'G' 'Z' 'P' 'O' 'U' '7' '4' 'N' 'B' '_' '1' 'K' 'R' '0' 'P'\n",
      " 'T' '{' '}' 'V' '7' '9' '5' 'N' 'H' 'P' 'S' '}' 'D' '_' 'I' 'R' 'S' 'H'\n",
      " 'P' 'T' 'D' '2' 'R' 'F' '_' 'E' 'X' '5' '!' 'Z' 'F' '_' '6' 'R' 'B' 'S'\n",
      " 'H' 'U']\n",
      "110\n",
      "(110,)\n",
      "embeddings\n",
      "[[-0.38804208 -0.82960969  0.28498215 ...  0.84272571  0.18395522\n",
      "   1.38538893]\n",
      " [ 0.23968969  0.49330195  0.29123344 ... -0.17795812 -0.34906333\n",
      "  -0.36859668]\n",
      " [ 0.06171513 -0.5289904   0.07278071 ...  0.64063249  0.06371699\n",
      "   0.45784946]\n",
      " ...\n",
      " [ 0.50472927 -0.88382723  0.79664604 ...  0.7187068  -0.18154163\n",
      "   1.05677205]\n",
      " [ 0.52531155 -1.00317296  0.32061688 ...  0.97876935  0.20046845\n",
      "   0.57602139]\n",
      " [ 0.05885257 -0.16288486 -0.00894871 ... -0.13074514 -0.11173366\n",
      "   0.41113626]]\n",
      "110\n",
      "(110, 512)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(r'C:\\Users\\User\\Desktop\\HackTheBox\\Lost in Hyperspace\\token_embeddings.npz')\n",
    "lst = data.files\n",
    "for item in lst:\n",
    "    print(item)\n",
    "    print(data[item])\n",
    "    print(len(data[item]))\n",
    "    print(data[item].shape)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(data['tokens'])):\n",
    "    if data['tokens'][i] == 'H':\n",
    "        print(\"H have next position \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flag HYTRBW8IRPLH59}!4-!{FOIURTEQW645#Z4XNLEPOKGEFISDUVBMA{{DFPVAZX845CMNBVE}77}SFDCE123____HTB{L0ST_1N_TH3_SP1R4L}\n"
     ]
    }
   ],
   "source": [
    "#we have two tokens H we will try first. All positions are 26, 80, 89, 108\n",
    "flag = 'H'\n",
    "number = 26\n",
    "flag_len = 1\n",
    "used_numbers = []\n",
    "while flag_len != 110:\n",
    "    min = 1000000\n",
    "    next_min = None\n",
    "    for k in range(len(data['tokens'])):\n",
    "        if k != number:\n",
    "            distance = np.linalg.norm(data['embeddings'][number] - data['embeddings'][k])\n",
    "            if distance<min and (k not in used_numbers):\n",
    "                min = distance\n",
    "                next_min = k\n",
    "\n",
    "    used_numbers.append(number)\n",
    "    flag += data['tokens'][next_min]\n",
    "    number = next_min\n",
    "    flag_len += 1\n",
    "print(\"Flag\", flag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
